\section{Background}
\label{sec:background}

In this section, we provide an overview of program optimization, partial evaluation, fault tolerance and the fault model considered in this paper.

\subsection{Program Optimization}
\label{sec:program_opt}
Program optimization can take place at various levels of the code generation process.
Software architectural design can greatly influence the overall performance of a program, especially when the programmer is able to plan ahead in coordination with the available system resources.
As an example, developers can minimize memory accesses by introducing caching in the software level.
In practice, however, many developers design software that is agnostic to specific system environments.
Program optimizations are assumed to be carried out in the latter parts of the code generation process. 

Compiler optimizations have been recognized as an effective way to optimize programs without impacting the software development workflow.
Techniques used in optimization can target multi-level components of a program starting from a single statement to a code block. 
Optimizations aiming at different code structures and program scopes include loop optimizations, data-flow optimizations, SSA-based optimizations, code generator optimizations, functional language optimizations and inter-procedural optimizations. While optimizations should generally improve a program's performance, it should not affect the correctness of the program.

\subsection{Partial Evaluation}
\label{sec:partial_evaluation}
Partial evaluation, also known as program specialization, is an optimization algorithm which, when given a program and some input data, can produce a specialized program. The specialized program will produce the same result as the original program, while gaining improved performance. Suppose $P$ is a program, and $P'$ is its specialized program. An instance is a program execution with a particular set of inputs. Then, $P'$ is a specialized program of $P$ if and only if:
\begin{enumerate}
\item Every instance of $P'$ is also an instance of $P$.
\item There exists instances of $P$ that are not instances of $P'$.
\end{enumerate}

\bigbreak

Partial evaluations are sometimes called program specializations since much partial evaluation work to date has concerned automatic compiler generation from an interpretive definition of a programming language.
In general, a partial evaluation produces a specialized version of a program where some arguments are statically known~\cite{Jones1996}. 

Partial evaluation techniques can be classified into two categories: online and offline specialization.
Offline specialization means that the program begins with a binding-time analysis that aims to place appropriate annotations on the program before reading the static input.
Online specialization undertakes program reduction decisions during the transformation phase. In this paper, we focus on online specialization, by assuming no programmer annotations. 

Partial evaluation is a powerful and general optimization technique and has wide applications in various fields such as scientific computing, domain-specific language engineering and generic programming.
It provides a unifying paradigm in compiler interpreters and automatic program generators.

\subsection{Fault Tolerance}
\label{sec:fault_tolerance}
Given the increasing complexity and importance of software systems in both scientific and industrial fields, program-level dependability has become a significant topic of interest.
Fault tolerance is the property of the system where it can continue to operate properly in the event of a failure caused by one or more faults.

Fault tolerant software is becoming increasing important in many application fields, which require high software reliability such as aviation control systems where even a single error can cause catastrophic results.
To counteract against such risks, resilient software systems deploy various kinds of redundancy.
Examples include recovery blocks, N-version programming and self-checking software.
While these measures improve software fault tolerance, they also incur a performance penalty with larger execution codes.
Since programs typically undergo compile-time optimizations, there is a need to understand the impact of different compiler optimizations on software reliability.

In this paper, we explore the error resilience of program partial evaluations. We refer to the error resilience of a program as its ability to withstand faults, not only arising from hardware, but also software faults without violating program specifications. 

\subsection{Fault Model}
\label{sec:fault_model}

In this study, we refer to faults as the defects in the system, errors as observable deviations from the original system behaviour, and failures as violations of design specifications.

In our fault model, we consider transient hardware and software faults, and permanent hardware defects.
We do not consider permanent software faults that occur as a result of implementation mistakes.
We focus on faults that are outside the direct control of programmers.
Transient hardware faults include cosmic alpha particle strikes on processor chips that cause a single bit to be flipped.
Permanent hardware faults encompass irrecoverable chip failures, leading to a stuck at bit fault.
Transient software faults include data and function call corruptions. 
We assume that these faults occur during program execution, either in the hardware or software of the system. 

Errors are defined as deviations between the golden and faulty runs of a program.
Typically, an instruction/data trace is taken over the course of program execution. 
These traces are compared and conflicts between traces are considered errors.

We consider faulty programs to fail if program execution results in silent data corruptions (SDC's), crashes or hangs. For the purpose of this study, we will ignore benign faults - faults that do not lead to a failure.

To simulate this prescribed fault model, we perform software implemented fault injection (SWIFI) on the benchmarks.  
Fault injection is one of the commonly deployed techniques to evaluate the error resilience of a program by introducing faults in a systematic manner and enabling monitoring of the system throughout the injection phase.
